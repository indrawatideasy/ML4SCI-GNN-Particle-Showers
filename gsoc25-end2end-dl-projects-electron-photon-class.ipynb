{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11267884,"sourceType":"datasetVersion","datasetId":7043464},{"sourceId":11268088,"sourceType":"datasetVersion","datasetId":7043609}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-04T04:48:51.209144Z","iopub.execute_input":"2025-04-04T04:48:51.209434Z","iopub.status.idle":"2025-04-04T04:48:52.057881Z","shell.execute_reply.started":"2025-04-04T04:48:51.209400Z","shell.execute_reply":"2025-04-04T04:48:52.057042Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/input/single-electron/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\n/kaggle/input/photon-data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 1. Introduction\nThis report describes a deep learning approach to classify image-based data of photons and electrons. The objective is to distinguish between photon and electron events using a convolutional neural network (CNN), specifically leveraging the ResNet18 architecture in PyTorch.","metadata":{}},{"cell_type":"markdown","source":"## 2. Environment Setup\n\nInstall necessary libraries:","metadata":{}},{"cell_type":"code","source":"!pip install torch torchvision torchaudio\n!pip install numpy matplotlib scikit-learn\n!pip install h5py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T04:49:02.358173Z","iopub.execute_input":"2025-04-04T04:49:02.358464Z","iopub.status.idle":"2025-04-04T04:49:12.889302Z","shell.execute_reply.started":"2025-04-04T04:49:02.358443Z","shell.execute_reply":"2025-04-04T04:49:12.888261Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.12.1)\nRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->h5py) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->h5py) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->h5py) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->h5py) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->h5py) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->h5py) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.3->h5py) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.3->h5py) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.3->h5py) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.3->h5py) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.3->h5py) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"These packages are required for deep learning (PyTorch), data handling (NumPy, HDF5), and visualization.","metadata":{}},{"cell_type":"markdown","source":"## 3. Dataset Loading and Preprocessing\n\nLoad photon and electron images from HDF5 files:","metadata":{}},{"cell_type":"code","source":"import h5py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nimport matplotlib.pyplot as plt\n\n# Load dataset\ndef load_data(photon_path, electron_path):\n    # Load photon data from HDF5\n    with h5py.File(photon_path, \"r\") as f:\n        photons = f[\"X\"][:]  # Replace \"X\" with the actual dataset name inside the HDF5 file\n    \n    # Load electron data from HDF5\n    with h5py.File(electron_path, \"r\") as f:\n        electrons = f[\"X\"][:]  # Replace \"X\" with the actual dataset name inside the HDF5 file\n    \n    # Label assignment: Photon (1), Electron (0)\n    photon_labels = np.ones(len(photons))\n    electron_labels = np.zeros(len(electrons))\n\n    # Combine data\n    X = np.concatenate((photons, electrons), axis=0)  # Shape: (num_samples, height, width, channels)\n    y = np.concatenate((photon_labels, electron_labels), axis=0)\n\n    # Normalize data\n    X = X.astype(np.float32) / 255.0  # Scale pixel values to range [0,1]\n\n    return X, y\n\n# Paths to HDF5 files\nphoton_path = \"/kaggle/input/photon-data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\"\nelectron_path = \"/kaggle/input/single-electron/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\"\n\n# Load the dataset\nX, y = load_data(photon_path, electron_path)\n\n# Convert to PyTorch tensors\nX_tensor = torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2)  # Convert to (N, C, H, W)\ny_tensor = torch.tensor(y, dtype=torch.long)\n\n# Split into train (80%) and test (20%) sets\ntrain_size = int(0.8 * len(X))\ntest_size = len(X) - train_size\ntrain_dataset, test_dataset = random_split(TensorDataset(X_tensor, y_tensor), [train_size, test_size])\n\n# Dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Print shapes for verification\nprint(\"Train dataset size:\", len(train_dataset))\nprint(\"Test dataset size:\", len(test_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T04:49:15.741552Z","iopub.execute_input":"2025-04-04T04:49:15.741849Z","iopub.status.idle":"2025-04-04T04:49:38.210457Z","shell.execute_reply.started":"2025-04-04T04:49:15.741824Z","shell.execute_reply":"2025-04-04T04:49:38.209730Z"}},"outputs":[{"name":"stdout","text":"Train dataset size: 398400\nTest dataset size: 99600\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 4. Model Definition (ResNet15)","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\nfrom torchvision.models import resnet18\n\nclass ResNet15(nn.Module):\n    def __init__(self, num_classes=2):\n        super(ResNet15, self).__init__()\n        self.resnet = resnet18(pretrained=False)  # Menggunakan ResNet18 sebagai baseline\n        self.resnet.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1, bias=False)  # Ubah input ke 2 channel\n        self.resnet.fc = nn.Linear(512, num_classes)  # Ubah output layer\n    \n    def forward(self, x):\n        return self.resnet(x)\n\n# Inisialisasi model\nmodel = ResNet15().to('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T04:49:47.389919Z","iopub.execute_input":"2025-04-04T04:49:47.390410Z","iopub.status.idle":"2025-04-04T04:49:50.292679Z","shell.execute_reply.started":"2025-04-04T04:49:47.390382Z","shell.execute_reply":"2025-04-04T04:49:50.292013Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 5. Training the Model","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nepochs = 10\nlearning_rate = 0.001\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n\n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {100 * correct/total:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T04:50:15.089282Z","iopub.execute_input":"2025-04-04T04:50:15.089725Z","iopub.status.idle":"2025-04-04T05:33:27.916481Z","shell.execute_reply.started":"2025-04-04T04:50:15.089700Z","shell.execute_reply":"2025-04-04T05:33:27.915711Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.6143, Accuracy: 66.74%\nEpoch [2/10], Loss: 0.5691, Accuracy: 71.34%\nEpoch [3/10], Loss: 0.5602, Accuracy: 72.07%\nEpoch [4/10], Loss: 0.5552, Accuracy: 72.35%\nEpoch [5/10], Loss: 0.5519, Accuracy: 72.65%\nEpoch [6/10], Loss: 0.5492, Accuracy: 72.77%\nEpoch [7/10], Loss: 0.5469, Accuracy: 72.92%\nEpoch [8/10], Loss: 0.5445, Accuracy: 73.08%\nEpoch [9/10], Loss: 0.5430, Accuracy: 73.23%\nEpoch [10/10], Loss: 0.5416, Accuracy: 73.33%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 6. Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Evaluation function\ndef evaluate(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n    print(f\"Test Accuracy: {100 * correct/total:.2f}%\")\n\n# Run evaluation\nevaluate(model, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T05:33:27.917611Z","iopub.execute_input":"2025-04-04T05:33:27.917827Z","iopub.status.idle":"2025-04-04T05:33:44.059793Z","shell.execute_reply.started":"2025-04-04T05:33:27.917809Z","shell.execute_reply":"2025-04-04T05:33:44.059070Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 72.62%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Optimized Model 1","metadata":{}},{"cell_type":"code","source":".from torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\ndef load_data(photon_path, electron_path):\n    with h5py.File(photon_path, \"r\") as f:\n        photons = f[\"X\"][:]\n\n    with h5py.File(electron_path, \"r\") as f:\n        electrons = f[\"X\"][:]\n\n    photon_labels = np.ones(len(photons))\n    electron_labels = np.zeros(len(electrons))\n\n    X = np.concatenate((photons, electrons), axis=0)\n    y = np.concatenate((photon_labels, electron_labels), axis=0)\n\n    # Normalisasi dan ubah format ke channel-first (NCHW)\n    X = X.astype(np.float32) / 255.0\n    X = np.transpose(X, (0, 3, 1, 2))  # NHWC â†’ NCHW\n\n    return X, y\n\nphoton_path = \"/kaggle/input/photon-data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\"\nelectron_path = \"/kaggle/input/single-electron/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\"\n\nX, y = load_data(photon_path, electron_path)\n\n# Split dataset\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nX_train_tensor = torch.tensor(X_train)\ny_train_tensor = torch.tensor(y_train, dtype=torch.long)\nX_val_tensor = torch.tensor(X_val)\ny_val_tensor = torch.tensor(y_val, dtype=torch.long)\n\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T05:38:14.748555Z","iopub.execute_input":"2025-04-04T05:38:14.748873Z","iopub.status.idle":"2025-04-04T05:38:35.901667Z","shell.execute_reply.started":"2025-04-04T05:38:14.748853Z","shell.execute_reply":"2025-04-04T05:38:35.900666Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\nmodel = models.resnet18(pretrained=False)\n\n# Ganti layer pertama agar support 2 channels\nmodel.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n\n# Ganti output layer (2 kelas: photon & electron)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 2)  # Softmax untuk 2 kelas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T05:38:40.005205Z","iopub.execute_input":"2025-04-04T05:38:40.005740Z","iopub.status.idle":"2025-04-04T05:38:40.159004Z","shell.execute_reply.started":"2025-04-04T05:38:40.005715Z","shell.execute_reply":"2025-04-04T05:38:40.158035Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nimport torch.nn.functional as F\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\nlearning_rate = 0.0005\nweight_decay = 1e-2\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\nscheduler = StepLR(optimizer, step_size=3, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T06:52:33.654841Z","iopub.execute_input":"2025-04-04T06:52:33.655160Z","iopub.status.idle":"2025-04-04T06:52:33.662866Z","shell.execute_reply.started":"2025-04-04T06:52:33.655119Z","shell.execute_reply":"2025-04-04T06:52:33.662200Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"epochs = 20\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n\n    scheduler.step()\n\n    accuracy = 100 * correct / total\n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n\nprint(\"Training complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T06:52:57.802843Z","iopub.execute_input":"2025-04-04T06:52:57.803162Z","iopub.status.idle":"2025-04-04T08:03:45.514110Z","shell.execute_reply.started":"2025-04-04T06:52:57.803108Z","shell.execute_reply":"2025-04-04T08:03:45.513326Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/20], Loss: 0.5438, Accuracy: 73.14%\nEpoch [2/20], Loss: 0.5428, Accuracy: 73.16%\nEpoch [3/20], Loss: 0.5421, Accuracy: 73.24%\nEpoch [4/20], Loss: 0.5330, Accuracy: 73.91%\nEpoch [5/20], Loss: 0.5304, Accuracy: 74.02%\nEpoch [6/20], Loss: 0.5283, Accuracy: 74.20%\nEpoch [7/20], Loss: 0.5209, Accuracy: 74.65%\nEpoch [8/20], Loss: 0.5183, Accuracy: 74.84%\nEpoch [9/20], Loss: 0.5162, Accuracy: 74.95%\nEpoch [10/20], Loss: 0.5105, Accuracy: 75.28%\nEpoch [11/20], Loss: 0.5086, Accuracy: 75.46%\nEpoch [12/20], Loss: 0.5068, Accuracy: 75.52%\nEpoch [13/20], Loss: 0.5033, Accuracy: 75.74%\nEpoch [14/20], Loss: 0.5018, Accuracy: 75.79%\nEpoch [15/20], Loss: 0.5008, Accuracy: 75.90%\nEpoch [16/20], Loss: 0.4982, Accuracy: 76.04%\nEpoch [17/20], Loss: 0.4979, Accuracy: 76.07%\nEpoch [18/20], Loss: 0.4971, Accuracy: 76.09%\nEpoch [19/20], Loss: 0.4959, Accuracy: 76.14%\nEpoch [20/20], Loss: 0.4956, Accuracy: 76.17%\nTraining complete!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n\nval_acc = 100 * correct / total\nprint(f\"Validation Accuracy: {val_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:03:45.515186Z","iopub.execute_input":"2025-04-04T08:03:45.515488Z","iopub.status.idle":"2025-04-04T08:03:57.847560Z","shell.execute_reply.started":"2025-04-04T08:03:45.515457Z","shell.execute_reply":"2025-04-04T08:03:57.846643Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 71.51%\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 7. Conclusion and Suggestions\n\n* Final training accuracy: ~76%\n\n* Final test accuracy: ~71.5%\n\n### Suggestions for Improvement:\n\n* Apply image augmentation using torchvision.transforms\n\n* Add regularization (Dropout layers)\n\n* Tune hyperparameters (learning rate, scheduler, optimizer)\n\n* Add early stopping to prevent overfitting\n\n","metadata":{}}]}